{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TensorFlow Core Learning Algorithms**\n",
    "\n",
    "This notebook contains info about 4 funcdamental machine learning algorithms. we will apply each of these algorithm to unique problems and database before highlighting the use cases of each.\n",
    "\n",
    "#### The algorithms we will focus on include :\n",
    "- Linear Regression\n",
    "- Classification\n",
    "- Clustering\n",
    "- Hidden Markov Model\n",
    "\n",
    "it is worth noting that there are many tools within tensorflow that could be used to solve the problems we will see below. some tools that will give the most variety and are easiest to use.\n",
    "\n",
    "### **Linear Regression**\n",
    "\n",
    "Linear Regression is one of the most basic forms of machine learning and is used to predict numeric values.\n",
    "\n",
    "In this , we will use linear model to predict the survival rate of passengers from titanic dataset.\n",
    "\n",
    "### How it Works\n",
    "\n",
    "Before we dive in i will provide a very surface level explanation of the linear algorithm.\n",
    "\n",
    "Linear regression follows a very simple concept . if data points are related linearly we can generate **a line of bestfit** for these points and use it to predict future values.\n",
    "\n",
    "Lets take an example of data set with one feature and one label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import , division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output # Just for showing Output.\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data**\n",
    "\n",
    "data is the major part of machine learning ,In fact it's so important that most of what we will be focus on , cleaning and selecting appropriate data.\n",
    "\n",
    "The dataset we wil be following in here is the **titanic dataset** . it has tons of information about each passager on the ship. Ou first step is always to understand the data and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset.\n",
    "\n",
    "#training data \n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "\n",
    "# Testing data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "print(dftrain.head())\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **pd.read_csv()** method will return to us a new pandas dataframe. You can think of a dataframe like a table. In fact we can actually have a look at the table representation.\n",
    "\n",
    "We've decided to pop the \"survived\" column form our dataset and store it in a varaible. this Column simply tells us if the person survivied or not.\n",
    "\n",
    "To Look at the data we'll use the **.head()** method from pandas . this will show us 5 times in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000  First        C   \n",
       "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>First</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>D</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
       "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
       "1    male  54.0                   0      0  51.8625   First        E   \n",
       "2  female  58.0                   0      0  26.5500   First        C   \n",
       "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
       "4    male  34.0                   0      0  13.0000  Second        D   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     y  \n",
       "1  Southampton     y  \n",
       "2  Southampton     y  \n",
       "3  Southampton     y  \n",
       "4  Southampton     y  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfeval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    0\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    0\n",
       " Name: survived, dtype: int64,\n",
       " 0    0\n",
       " 1    0\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: survived, dtype: int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head() ,y_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sex                          male\n",
       " age                          22.0\n",
       " n_siblings_spouses              1\n",
       " parch                           0\n",
       " fare                         7.25\n",
       " class                       Third\n",
       " deck                      unknown\n",
       " embark_town           Southampton\n",
       " alone                           n\n",
       " Name: 0, dtype: object,\n",
       " sex                          male\n",
       " age                          35.0\n",
       " n_siblings_spouses              0\n",
       " parch                           0\n",
       " fare                         8.05\n",
       " class                       Third\n",
       " deck                      unknown\n",
       " embark_town           Southampton\n",
       " alone                           y\n",
       " Name: 0, dtype: object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.loc[0],dfeval.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      22.0\n",
       "1      38.0\n",
       "2      26.0\n",
       "3      35.0\n",
       "4      28.0\n",
       "       ... \n",
       "622    28.0\n",
       "623    25.0\n",
       "624    19.0\n",
       "625    28.0\n",
       "626    32.0\n",
       "Name: age, Length: 627, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so , above says it have 627 entires and 9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain.age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      410\n",
       "female    217\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain.sex.value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain['class'].value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000  First        C   \n",
       "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  survived  \n",
       "0  Southampton     n         0  \n",
       "1    Cherbourg     n         1  \n",
       "2  Southampton     y         1  \n",
       "3  Southampton     n         1  \n",
       "4   Queenstown     y         0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([dftrain , y_train] , axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "female    1.0\n",
       "male      0.0\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([dftrain , y_train] , axis=1).head().groupby('sex').survived.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='sex'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([dftrain , y_train] , axis=1).head().groupby('sex').survived.mean().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '% survive')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([dftrain , y_train] , axis=1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing this inforamtion we should notice the following :\n",
    "\n",
    "- The majority of passengers are in their 20s or 30s.\n",
    "- The majority of passengers are male.\n",
    "- The majority of passengers are in 'Thrid' Class.\n",
    "- Females have a much higer chance of survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training vs Testing Data\n",
    "\n",
    "You may have noticed that we loaded two different datasets above. This is because whe we trian models we need two sets of data:\n",
    "\n",
    "The **training** data is what we feed to the model so that it can develop and learn . it is usually a much larger size than the testing data.\n",
    "\n",
    "The **testing** data is what we use to evaluate the model and see how well it is performing . we must use a separate set of data that the model has not been trianed on to evaluate it. CAn you think of why this is ?\n",
    "\n",
    "Well , the point of our model is to be able to make predictions on NEW data, data that we never seen before. if we simply test the model on the data that it has already seen we cannot measure its accuracy accuratly. We can't be sure that the model hasn't simply memorized our training data. This is why we need our testing and training data to be separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((627, 9), (264, 9))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.shape,dfeval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Categorical data ?**\n",
    "\n",
    "**Answer** : **Categorical data** is the data which is not numeric and has different categories, there is going to be like a specific set of different categories in a dataset.\n",
    "\n",
    "We change these categorical data into numeric data somehow since, model does not know about these strign data instead numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Features Columns**\n",
    "\n",
    "In our dataset we have two different kinds of information : \n",
    "- Categorical\n",
    "- Numeric\n",
    "\n",
    "Our **categorical data** is anything that is not numeric! For example, the sex column does not use numbers, it use numbers , it uses words \"male\" and \"female\".\n",
    "\n",
    "Before we continue and create/train a model we must convert our categories data into numeric data. We can do this by encoding each category with an integer(ex: male=1 , female=2)\n",
    "\n",
    "Fortunately for us TensorFLow has some tools to help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex' , 'n_siblings_spouses','parch' , 'class' , 'deck' , 'embark_town','alone']\n",
    "\n",
    "NUMERIC_COLUMNS = ['age' , 'fare']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "\n",
    "for feature_name in CATEGORICAL_COLUMNS :\n",
    "#     gets a list of all unique values from given feature column\n",
    "    vocabulary = dftrain[feature_name].unique()\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name , vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS :\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name , dtype=tf.float32))\n",
    "\n",
    "\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>vocabulary_list</th>\n",
       "      <th>dtype</th>\n",
       "      <th>default_value</th>\n",
       "      <th>num_oov_buckets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>(male, female)</td>\n",
       "      <td>&lt;dtype: 'string'&gt;</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_siblings_spouses</td>\n",
       "      <td>(1, 0, 3, 4, 2, 5, 8)</td>\n",
       "      <td>&lt;dtype: 'int64'&gt;</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>parch</td>\n",
       "      <td>(0, 1, 2, 5, 3, 4)</td>\n",
       "      <td>&lt;dtype: 'int64'&gt;</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class</td>\n",
       "      <td>(Third, First, Second)</td>\n",
       "      <td>&lt;dtype: 'string'&gt;</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deck</td>\n",
       "      <td>(unknown, C, G, A, B, D, F, E)</td>\n",
       "      <td>&lt;dtype: 'string'&gt;</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>embark_town</td>\n",
       "      <td>(Southampton, Cherbourg, Queenstown, unknown)</td>\n",
       "      <td>&lt;dtype: 'string'&gt;</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alone</td>\n",
       "      <td>(n, y)</td>\n",
       "      <td>&lt;dtype: 'string'&gt;</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>age</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;dtype: 'float32'&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fare</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;dtype: 'float32'&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  key                                vocabulary_list  \\\n",
       "0                 sex                                 (male, female)   \n",
       "1  n_siblings_spouses                          (1, 0, 3, 4, 2, 5, 8)   \n",
       "2               parch                             (0, 1, 2, 5, 3, 4)   \n",
       "3               class                         (Third, First, Second)   \n",
       "4                deck                 (unknown, C, G, A, B, D, F, E)   \n",
       "5         embark_town  (Southampton, Cherbourg, Queenstown, unknown)   \n",
       "6               alone                                         (n, y)   \n",
       "7                 age                                           (1,)   \n",
       "8                fare                                           (1,)   \n",
       "\n",
       "               dtype       default_value  num_oov_buckets  \n",
       "0  <dtype: 'string'>                  -1              0.0  \n",
       "1   <dtype: 'int64'>                  -1              0.0  \n",
       "2   <dtype: 'int64'>                  -1              0.0  \n",
       "3  <dtype: 'string'>                  -1              0.0  \n",
       "4  <dtype: 'string'>                  -1              0.0  \n",
       "5  <dtype: 'string'>                  -1              0.0  \n",
       "6  <dtype: 'string'>                  -1              0.0  \n",
       "7               None  <dtype: 'float32'>              NaN  \n",
       "8               None  <dtype: 'float32'>              NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.DataFrame(feature_columns)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Process\n",
    "\n",
    "So, we are almost done preparing our dataset and i feel as though it's a good time to explain how our model is trained.Specifically how input data is fed to our model.\n",
    "\n",
    "For thsi specific model data is going to be streamed into it in small batches of 32. This means we will not feed the entire dataset to our model at once, but simply batches of entires. We will actually feed feed these batches to our model multiple times according to the number of **epoches**.\n",
    "\n",
    "An epoch is simply one stream of our entire dataset. The number of epochs we define is the amount of times our model will see the entire dataset. we use multiple epochs in hope that after seeing the same data multiple times the model will better determine how to estimate it. But in these multiple epochs ,we feed the same data in different order because as we feed data to model the very first line of bestfit is quite weird or unaccurate so, we feed it multiple times to make that line of bestfit more accurate and better.\n",
    "\n",
    "Ex. if we have 10 epochs , our model will see the same dataset 10 times.\n",
    "\n",
    "Since, we need to feed our data in batches and multiple times we need to create something called an input function. The input function simply defines how our dataset will be converted into batches at each epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Input Function**\n",
    "\n",
    "The Tensorflow model we are going to use requires that data we pass it comes in as a tf.data.Dataset object. This means we must create a input function that can convert our current pandas dataframe into that object.\n",
    "\n",
    "This is seemigly complicated input function, this is straight form the TensorFlow Documentation <a href=\"https://www.tensorflow.org/tutorials/estimator/linear\">Click here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df , label_df , num_epochs=10, shuffle=True , batch_size=32):\n",
    "    def input_function(): #inner function, this will be returned\n",
    "        # Create tf.data.Dataset object with data and its label\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle :\n",
    "            ds = ds.shuffle(1000) #random order of data\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)#split dataset into batches of 32 and repeat process for number of epochs\n",
    "        return ds # return a batch of dataset\n",
    "    return input_function # return a function object for use\n",
    "\n",
    "# here we will call the input function that was return to us to get a data\n",
    "train_input_fn = make_input_fn(dftrain , y_train) \n",
    "eval_input_fn = make_input_fn(dfeval , y_eval , num_epochs=1 , shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "In this , we are going to use a linear estimator to utilize the linear regression algorithm.\n",
    "\n",
    "Creating one is actually pretty easy! have a look below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\india\\AppData\\Local\\Temp\\tmpm18ely9b\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\india\\\\AppData\\\\Local\\\\Temp\\\\tmpm18ely9b', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "# we create a linear estimator by passing the feature columns we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310606\n",
      "{'accuracy': 0.7310606, 'accuracy_baseline': 0.625, 'auc': 0.81943685, 'auc_precision_recall': 0.76004285, 'average_loss': 0.5844327, 'label/mean': 0.375, 'loss': 0.586176, 'precision': 0.6076923, 'prediction/mean': 0.5310714, 'recall': 0.7979798, 'global_step': 200}\n"
     ]
    }
   ],
   "source": [
    "linear_est.train(train_input_fn) #train\n",
    "result = linear_est.evaluate(eval_input_fn) # get model metrics/stats by testing on testing data\n",
    "\n",
    "clear_output() # it clears the console output\n",
    "print(result['accuracy']) # the result varaible is simply a dict of stats about our model\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\india\\AppData\\Local\\Temp\\tmpm18ely9b\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "sex                          male\n",
      "age                          34.0\n",
      "n_siblings_spouses              0\n",
      "parch                           0\n",
      "fare                         13.0\n",
      "class                      Second\n",
      "deck                            D\n",
      "embark_town           Southampton\n",
      "alone                           y\n",
      "Name: 4, dtype: object\n",
      "1\n",
      "Chance of Survival :  0.47066766\n",
      "Chance of not Survival :  0.5293323\n"
     ]
    }
   ],
   "source": [
    "#predicting from model/result\n",
    "result = list(linear_est.predict(eval_input_fn))\n",
    "print(dfeval.loc[4])\n",
    "print(y_eval.loc[4])\n",
    "print(\"Chance of Survival : \",result[4]['probabilities'][1])\n",
    "print(\"Chance of not Survival : \",result[4]['probabilities'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classification**\n",
    "\n",
    "Now that we've covered linear regression it is time to talk about classification . Where regression was used to predict a numeric value.\n",
    "Classification is used to separate data points into classes of different labels.In this example , we will use a tensorFlow estimator to classify flowers.\n",
    "\n",
    "Since we've touched on how estimators work earlier we're going a bit quicker though this example.\n",
    "\n",
    "This section is based on following tensorflow website : \n",
    "<a href=\"https://www.tensorflow.org/tutorials/estimator/premade\">https://www.tensorflow.org/tutorials/estimator/premade</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import and Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import , division , print_function , unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "This specific dataset separates flowers into 3 different classes of species\n",
    "- Setosa\n",
    "- Versicolor\n",
    "- Virginica\n",
    "\n",
    "The information about each flower is the following :\n",
    "- sepal length\n",
    "- sepal width\n",
    "- petal length\n",
    "- petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now defining CSV column name and species\n",
    "CSV_COLUMN_NAMES = ['SepalLength' , 'SepalWidth' , 'PetalLength' , 'PetalWidth' , 'Species']\n",
    "SPECIES = ['Setosa' , 'Versicolor' , 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some constant to help us later on\n",
    "\n",
    "# it will save the CSV file from link and named it as \"iris_training.csv\"\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "\n",
    "# it will save the CSV file from link and named it as \"iris_test.csv\"\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\" , \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path , names=CSV_COLUMN_NAMES , header=0)\n",
    "test = pd.read_csv(test_path , names=CSV_COLUMN_NAMES , header=0)\n",
    "# Here we use keras (a module inside of tensorFlow) to grab our datasets and read them into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is our data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          5.9         3.0          4.2         1.5\n",
       "1          6.9         3.1          5.4         2.1\n",
       "2          5.1         3.3          1.7         0.5\n",
       "3          6.0         3.4          4.5         1.6\n",
       "4          5.5         2.5          4.0         1.3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape # now , train have 120 entries and 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape # it have 30 entries and 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FUNCTION\n",
    "\n",
    "def input_fn(features , labels , training=True , batch_size=256):\n",
    "    # Convert the inputs to Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features) , labels))\n",
    "    \n",
    "    #  Shuffle and repeat if you are in training mode\n",
    "    if training : \n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "        \n",
    "    return dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featues columns describe how to use the input\n",
    "\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "# print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Building The Model\n",
    "\n",
    "Now, we are ready to choose a model. For classification tasks there are variety of different estimators/models that we can pick from Some Options listed below :\n",
    "- DNNClassifier (Deep Neural Network)\n",
    "- LinearClassifier\n",
    "\n",
    "We can choose either model but the DNN seems to be the best choice. This is because we may not be able to find a linear correspondence in our data.\n",
    "\n",
    "so, Let build our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\india\\AppData\\Local\\Temp\\tmphbpt2jcs\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\india\\\\AppData\\\\Local\\\\Temp\\\\tmphbpt2jcs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Building Model\n",
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=my_feature_columns,\n",
    "                                    # Two diffen layers of 30 and 10 nodes respectively.\n",
    "                                       hidden_units=[30,10],\n",
    "                                    # The model must choose between 3 classes.\n",
    "                                       n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\india\\AppData\\Local\\Temp\\tmphbpt2jcs\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.4874941, step = 0\n",
      "INFO:tensorflow:global_step/sec: 177.22\n",
      "INFO:tensorflow:loss = 0.97760516, step = 100 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.266\n",
      "INFO:tensorflow:loss = 0.87034404, step = 200 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.125\n",
      "INFO:tensorflow:loss = 0.8147954, step = 300 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.267\n",
      "INFO:tensorflow:loss = 0.74618286, step = 400 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.666\n",
      "INFO:tensorflow:loss = 0.7224504, step = 500 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.68\n",
      "INFO:tensorflow:loss = 0.6894004, step = 600 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.178\n",
      "INFO:tensorflow:loss = 0.6565052, step = 700 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.1\n",
      "INFO:tensorflow:loss = 0.63082093, step = 800 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.388\n",
      "INFO:tensorflow:loss = 0.59725827, step = 900 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.753\n",
      "INFO:tensorflow:loss = 0.56467414, step = 1000 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.976\n",
      "INFO:tensorflow:loss = 0.5515818, step = 1100 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.836\n",
      "INFO:tensorflow:loss = 0.5294955, step = 1200 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.068\n",
      "INFO:tensorflow:loss = 0.504319, step = 1300 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.225\n",
      "INFO:tensorflow:loss = 0.5106098, step = 1400 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.805\n",
      "INFO:tensorflow:loss = 0.48768577, step = 1500 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.303\n",
      "INFO:tensorflow:loss = 0.48262608, step = 1600 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.502\n",
      "INFO:tensorflow:loss = 0.46089435, step = 1700 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.177\n",
      "INFO:tensorflow:loss = 0.46092567, step = 1800 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.421\n",
      "INFO:tensorflow:loss = 0.44917968, step = 1900 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.872\n",
      "INFO:tensorflow:loss = 0.4320503, step = 2000 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.421\n",
      "INFO:tensorflow:loss = 0.42563826, step = 2100 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.425\n",
      "INFO:tensorflow:loss = 0.42492697, step = 2200 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.74\n",
      "INFO:tensorflow:loss = 0.40658128, step = 2300 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.234\n",
      "INFO:tensorflow:loss = 0.40208638, step = 2400 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.1\n",
      "INFO:tensorflow:loss = 0.389203, step = 2500 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.033\n",
      "INFO:tensorflow:loss = 0.39431295, step = 2600 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.018\n",
      "INFO:tensorflow:loss = 0.37678218, step = 2700 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.873\n",
      "INFO:tensorflow:loss = 0.37982932, step = 2800 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.069\n",
      "INFO:tensorflow:loss = 0.37308013, step = 2900 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.724\n",
      "INFO:tensorflow:loss = 0.36940306, step = 3000 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.173\n",
      "INFO:tensorflow:loss = 0.36423755, step = 3100 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.243\n",
      "INFO:tensorflow:loss = 0.3647409, step = 3200 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.465\n",
      "INFO:tensorflow:loss = 0.34838623, step = 3300 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.301\n",
      "INFO:tensorflow:loss = 0.33406508, step = 3400 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.016\n",
      "INFO:tensorflow:loss = 0.3342536, step = 3500 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.667\n",
      "INFO:tensorflow:loss = 0.33059552, step = 3600 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.566\n",
      "INFO:tensorflow:loss = 0.32656348, step = 3700 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.65\n",
      "INFO:tensorflow:loss = 0.32267794, step = 3800 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.972\n",
      "INFO:tensorflow:loss = 0.3177808, step = 3900 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.168\n",
      "INFO:tensorflow:loss = 0.3127911, step = 4000 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.288\n",
      "INFO:tensorflow:loss = 0.32425874, step = 4100 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.52\n",
      "INFO:tensorflow:loss = 0.30695683, step = 4200 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.452\n",
      "INFO:tensorflow:loss = 0.30702543, step = 4300 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.742\n",
      "INFO:tensorflow:loss = 0.3026234, step = 4400 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.698\n",
      "INFO:tensorflow:loss = 0.2964118, step = 4500 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.643\n",
      "INFO:tensorflow:loss = 0.2872826, step = 4600 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.636\n",
      "INFO:tensorflow:loss = 0.29618073, step = 4700 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.494\n",
      "INFO:tensorflow:loss = 0.28301728, step = 4800 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.594\n",
      "INFO:tensorflow:loss = 0.29050934, step = 4900 (0.435 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\india\\AppData\\Local\\Temp\\tmphbpt2jcs\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.28029138.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x27b805f1a00>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now , Training Model\n",
    "classifier.train(\n",
    "    # we include lambda to avoid creating an inner function previously.\n",
    "    input_fn=lambda: input_fn(train , train_y ,training=True),\n",
    "    steps=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing to explain here is the **steps** arguemnt. This simply tells \n",
    "the classifier to run 5000 steps. Try modifying this and seeing if your results\n",
    "change.Keep in mind that more is not always better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation**\n",
    "\n",
    "Now, lets see how this trained model does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-02-25T18:09:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\india\\AppData\\Local\\Temp\\tmphbpt2jcs\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.56126s\n",
      "INFO:tensorflow:Finished evaluation at 2022-02-25-18:09:56\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.96666664, average_loss = 0.32458597, global_step = 5000, loss = 0.32458597\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\india\\AppData\\Local\\Temp\\tmphbpt2jcs\\model.ckpt-5000\n",
      "\n",
      "Testing set accuracy : 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn = lambda: input_fn(test , test_y , training=False)\n",
    ")\n",
    "print(\"\\nTesting set accuracy : {accuracy:0.3f}\\n\".format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice :** This time we didn't specifiy the number of steps. This is because during evaluation the model will only look at the testing data one time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Predictions**\n",
    "\n",
    "Now that we have a trained model it's time to use it to make predictions.Below is a script that allows you to type features of a flower and see a prediction for its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepalLength\n",
      "SepalWidth\n",
      "PetalLength\n",
      "PetalWidth\n",
      "{'SepalLength': [2.4], 'SepalWidth': [2.6], 'PetalLength': [6.5], 'PetalWidth': [6.3]}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\india\\AppData\\Local\\Temp\\tmphbpt2jcs\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'logits': array([-7.3103437, -2.5219896,  6.481322 ], dtype=float32), 'probabilities': array([1.0240041e-06, 1.2298660e-04, 9.9987602e-01], dtype=float32), 'class_ids': array([2], dtype=int64), 'classes': array([b'2'], dtype=object), 'all_class_ids': array([0, 1, 2]), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "prediction is 'Virginica' (100.0%)\n"
     ]
    }
   ],
   "source": [
    "def input_fn(features , batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    print(features)\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength' , 'SepalWidth' , 'PetalLength' , 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "# In this code space script is used to predict what kind of Species below data is.\n",
    "labels = [2.4,2.6,6.5,6.3]\n",
    "\n",
    "for i in range(0,4) :\n",
    "    print(features[i])\n",
    "    predict[features[i]] = [float(labels[i])]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions :\n",
    "    print(pred_dict)\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(\"prediction is '{}' ({:.1f}%)\".format(SPECIES[class_id],100*probability))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SepalLength': [5.1, 5.9, 6.9], 'SepalWidth': [3.3, 3.0, 3.1], 'PetalLength': [1.7, 4.2, 5.4], 'PetalWidth': [0.5, 1.5, 2.1]}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\india\\AppData\\Local\\Temp\\tmphbpt2jcs\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[0.86103874 0.13377796 0.00518334]\n",
      "Setosa  expectation/probability :  0.86103874\n",
      "[0.07022008 0.62236595 0.30741394]\n",
      "Versicolor  expectation/probability :  0.62236595\n",
      "[0.00521415 0.27968928 0.7150966 ]\n",
      "Virginica  expectation/probability :  0.7150966\n"
     ]
    }
   ],
   "source": [
    "# Here is some example input and expected classes you can try alone\n",
    "expected = ['Setosa' , 'Versicolor' , 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength' : [5.1,5.9,6.9],\n",
    "    'SepalWidth' : [3.3,3.0,3.1],\n",
    "    'PetalLength' : [1.7,4.2,5.4],\n",
    "    'PetalWidth' : [0.5,1.5,2.1],\n",
    "}\n",
    "\n",
    "prediction = classifier.predict(input_fn = lambda : input_fn(predict_x))\n",
    "for predict in prediction:\n",
    "    class_id = predict['class_ids'][0]\n",
    "    print(predict['probabilities'])\n",
    "    print(expected[class_id],\" expectation/probability : \",predict['probabilities'][class_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clustering**\n",
    "\n",
    "Now that we've covered regression and classification it's time to talk about clustering data!\n",
    "\n",
    "Clustering is unsupervised Machine Learning technique that involves the grouping of data points. Clustering only works for a very specific problems.And we use clustering, when you have bunch of input informationor features, you don't have any labels or open information. In theory , data points that are in the same group should have similar properties and /or features , while data points in different groups should have highly dissimilar properties and/or features.\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68\">Link to view</a>\n",
    "\n",
    "Unfortunatly ,  there are issue with the current version of TensorFlow and the implementation for KMeans. This menas we cannot use Kmeans without writing the algorthm from scratch. We aren't quite at that level yet so we'll jsut explain the basics of clustering for now.\n",
    "\n",
    "**Basic Algorithm for KMeans**\n",
    "- Step 1 : Randomly pick K points toplace K centroids.\n",
    "- Step 2 : Assign all of the data points to centroids by distance. Th closest centroid to a point is the one it is assigned to.\n",
    "- Step3 : Average all of the points belong to each centroid to find the middle of those clusters (center of mass). Place the corresponding centroids into that position.\n",
    "- Step4 : Reassign every point once again to the closest centroid.\n",
    "- Step5 : Repeat step3-4 until no point changes which centroid it belong to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hidden Markov Models**\n",
    "\n",
    "*The Hidden Markov Model* is a finite set of states, each of which is associated with a (generally multidimensional) probability distribution. Transition among the states are governed by a set of probabilities called *Transition Probability*.<br> <a href=\"http://jedlik.phy.bme.hu/~gerjanos/HMM/node4.html\">http://jedlik.phy.bme.hu/~gerjanos/HMM/node4.html</a>\n",
    "\n",
    "A hidden markov model works with probabilities to predict future events or states. In this section we will know how to create a hidden markov model that can predict the weather (weather forecasting).\n",
    "\n",
    "This is from below Tensor flow tutorial : <br>\n",
    "<a href=\"https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel\">https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data**\n",
    "\n",
    "Lets start by discussing the type of data we use when we work with a hidden markov model.\n",
    "\n",
    "For Hidden Markov Model , we are only interested in probability distributions that have to do with states.previously ,we worked with large datasets og 100s of different entires. For a markov model we are only interested in probability distribution tha have to do with states. In markov model , we don't need 100s of data entires in fact , all we need is just constant values for probability and transition distribution and observation distributions.\n",
    "\n",
    "we can find these probabilities from large datasets or may already have these values. We'll run through an example in a second that should clear some things up , nut lets discuss the components of a markov model.\n",
    "\n",
    "**States :** In each markov model we have a finite set of states. These states could be something like \"warm\" and \"cold\" or \"high\" and \"low\" or even \"red\" , \"green\" and \"blue\". These states are \"hidden\" within the model , which means we do not directly observe them.\n",
    "\n",
    "**Observations :** Each state has a particular outcome or observation assciated with it based on a probability distribution. An example of this is the following : *On a hot day Jimmy has a 80% chance of being happy and a 20% chance of being sad.*\n",
    "\n",
    "**Transitions :** Each state will have a probabilty defining the likelyhood of transitioning to a different state. An example is the following : *a cold day has 30% chance of being followed by a hot day and 70% chance of being followed by another cold day.*\n",
    "\n",
    "TO create a hidden markov model we need :\n",
    "- States\n",
    "- Observation Distribution\n",
    "- Transition Distribution\n",
    "\n",
    "For our purpose we will assume we already have this information available as we attempt to predict the weather on agiven day ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-probability in c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.16.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-probability) (0.4.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-probability) (2.0.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-probability) (0.1.6)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-probability) (1.21.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-probability) (5.1.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-probability) (1.0.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\india\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-probability) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp # we are using a different module from tensorflow this time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Weather Model**\n",
    "\n",
    "Taken directly from the TensorFlow documentation \n",
    "(<a href=\"https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel\">https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will model a simple weather system and try to predict the temperature on each day given the following information :\n",
    "1. Cold days are encoded by a 0 and hot days encoded by a 1.\n",
    "2. The first day in our sequence has an 80% chance of being cold.\n",
    "3. A cold day has a 30% chance of being followed by a hot day.\n",
    "4. A hot day has a 20% chance of being followed by a cold day.\n",
    "5. On each day the temperature is normally distributed with mean and standard deviation 0 and 5 on a cold day and mean and standard deviation 15 and 10 on a hot day.\n",
    "\n",
    "If you are unfamiliar with standard deviation it can be put simply as the range of expected values.\n",
    "\n",
    "In this example , on a hot day the average temperature is 15 to 25.\n",
    "\n",
    "To model this in TensorFlow we will do the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions #loading tensorflow distribution probability module\n",
    "\n",
    "# A simple weather model.\n",
    "\n",
    "# Represent a cold day with 0 and a hot day with 1.\n",
    "# Suppose the first day of a sequence has a 0.8 chance of being cold.\n",
    "# We can model this using the categorical distribution:\n",
    "\n",
    "# we will get temperature as ascending order b/c we started from  cold day.\n",
    "initial_distribution = tfd.Categorical(probs=[0.8, 0.2]) # Refer to point 2 above\n",
    "\n",
    "# Suppose a cold day has a 30% chance of being followed by a hot day\n",
    "# and a hot day has a 20% chance of being followed by a cold day.\n",
    "# We can model this as:\n",
    "\n",
    "transition_distribution = tfd.Categorical(probs=[[0.7, 0.3],\n",
    "                                                 [0.2, 0.8]])# refers to points 3 and 4\n",
    "\n",
    "# Suppose additionally that on each day the temperature is\n",
    "# normally distributed with mean and standard deviation 0 and 5 on\n",
    "# a cold day and mean and standard deviation 15 and 10 on a hot day.\n",
    "# We can model this with:\n",
    "\n",
    "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.]) #refer to point 5 above\n",
    "# the loc argument represents the mean and scale is the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now created distributed variables to model our system and its time to create the hidden markov model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=initial_distribution,\n",
    "    transition_distribution=transition_distribution,\n",
    "    observation_distribution=observation_distribution,\n",
    "    num_steps=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of steps represents the number of days that we would like to predict inforamtion for . In this case, we've choosen 7 , an entire week.\n",
    "\n",
    "To get the **expected temperature** on each day we can do the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9999998 5.9999995 7.4999995 8.25      8.625     8.812501  8.90625  ]\n"
     ]
    }
   ],
   "source": [
    "mean = model.mean() #mean of partially defined tensor\n",
    "\n",
    "# due to the way Tensorflow works on a lower level we need to evaluate part of the graph.\n",
    "# from within a session to see the value of this tensor.\n",
    "\n",
    "# in the new version of tensorflow we need to use tf.compact.v1.Session() rather than just tf.Session\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(mean.numpy()) # this gives temperature on each 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
