{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "for this tutorial we will use the MNIST Fashion Dataset. This is a dataset that is included in keras.\n",
    "\n",
    "This dataset includes 60,000 images for training and 10,000 images for validation/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist  # load dataset\n",
    "\n",
    "#split into testing and training\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top' , 'Trouser','Pullover' ,'Dress','Coat',\n",
    "              'Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "\n",
    "# Squezing values of train and test image between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Neural Network Model\n",
    "# here this Sequential means passing data from one layer to other.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)), # input layer (1)\n",
    "    keras.layers.Dense(128, activation='relu'), # hidden layer (2)\n",
    "    keras.layers.Dense(10, activation='softmax') # Output layer (3)\n",
    "])\n",
    "\n",
    "# the number in keras.layers.Dense (hidden layer) is always be smaller than\n",
    "# the input we given but not too small\n",
    "\n",
    "# For output layer , number 10 above is number of class in which our \n",
    "# data is distributed here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', # optimizer algorithm for here its some algo named 'adam'\n",
    "    loss='sparse_categorical_crossentropy', #loss function\n",
    "    metrics = ['accuracy'] # Metrics used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0696 - accuracy: 0.9742\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0706 - accuracy: 0.9743\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0672 - accuracy: 0.9748\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0668 - accuracy: 0.9757\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0677 - accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0656 - accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0638 - accuracy: 0.9765\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0641 - accuracy: 0.9762\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0606 - accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0642 - accuracy: 0.9761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc957b6040>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images , train_labels ,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0613 - accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc956e9580>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some times lesser epochs are better\n",
    "model.fit(train_images , train_labels ,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6939 - accuracy: 0.8940\n",
      "Test accuracy :  0.8939999938011169  and Test loss :  0.6938758492469788\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = model.evaluate(test_images , test_labels , verbose=1)\n",
    "\n",
    "print(\"Test accuracy : \",test_acc,\" and Test loss : \",test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle boot with probability of 100.0\n",
      "Pullover with probability of 99.99985694885254\n",
      "Trouser with probability of 100.0\n",
      "Trouser with probability of 100.0\n",
      "Shirt with probability of 54.490768909454346\n",
      "Trouser with probability of 100.0\n",
      "Coat with probability of 100.0\n",
      "Shirt with probability of 99.90283250808716\n",
      "Sandal with probability of 100.0\n",
      "Sneaker with probability of 100.0\n"
     ]
    }
   ],
   "source": [
    "# prediction on rows for max probability\n",
    "for i in range(0,10):\n",
    "    index_max_prob = np.argmax(predictions[i])\n",
    "    predict = predictions[i][index_max_prob]\n",
    "    print(class_names[index_max_prob],\"with probability of\",predict*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
